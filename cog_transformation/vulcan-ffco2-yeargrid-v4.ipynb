{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c2cb82e3-0dc2-43c8-b63f-f59fdec6bd16",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Vulcan Fossil Fuel COâ‚‚ Emissions v4.0\n",
    "description: Documentation of data transformation & Validation\n",
    "author: Paridhi Parajuli \n",
    "date: August 20, 2024\n",
    "updated : June 17, 2025\n",
    "execute:\n",
    "  freeze: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456658d4-e4a8-472e-b69c-74754c3016ac",
   "metadata": {},
   "source": [
    "Updated on : June 17, 2025\n",
    "\n",
    "This script was used to transform the VULCAN dataset provided in Cloud Optimized GeoTIFF (COG) format for display in the Greenhouse Gas (GHG) Center with the calaulation of validation statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4cc6fa-0591-4a20-9abf-f926c0f33941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import re\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import glob\n",
    "import s3fs\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "import os\n",
    "import boto3\n",
    "from pyproj import CRS\n",
    "from rasterio.io import MemoryFile\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.enums import Resampling\n",
    "from rio_cogeo.cogeo import cog_translate\n",
    "from rio_cogeo.profiles import cog_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cc2b7-3339-4789-b42f-7f744c285e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data_acquisition_method\": \"s3\",\n",
    "    \"raw_data_bucket\" : \"gsfc-ghg-store\",\n",
    "    \"raw_data_prefix\": \"Vulcan/v4.0/grid.1km.mn\",\n",
    "    \"cog_data_bucket\": \"ghgc-data-store-develop\",\n",
    "    \"cog_data_prefix\": \"transformed_cogs/VULCAN_v4\",\n",
    "    \"date_fmt\" :\"%Y\",\n",
    "    \"transformation\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadf144-5485-4a47-a4e9-c37b717c0dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "s3_client = session.client(\"s3\")\n",
    "\n",
    "raw_data_bucket = config[\"raw_data_bucket\"]\n",
    "raw_data_prefix= config[\"raw_data_prefix\"]\n",
    "\n",
    "cog_data_bucket = config['cog_data_bucket']\n",
    "cog_data_prefix= config[\"cog_data_prefix\"]\n",
    "\n",
    "date_fmt=config['date_fmt']\n",
    "\n",
    "fs = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b52b7-6716-4ae5-9fcb-5b82d301b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_s3_keys(bucket, model_name, ext):\n",
    "    \"\"\"Get a list of all keys in an S3 bucket.\"\"\"\n",
    "    keys = []\n",
    "\n",
    "    kwargs = {\"Bucket\": bucket, \"Prefix\": f\"{model_name}/\"}\n",
    "    while True:\n",
    "        resp = s3_client.list_objects_v2(**kwargs)\n",
    "        for obj in resp[\"Contents\"]:\n",
    "            if obj[\"Key\"].endswith(ext) and \"historical\" not in obj[\"Key\"]:\n",
    "                keys.append(obj[\"Key\"])\n",
    "\n",
    "        try:\n",
    "            kwargs[\"ContinuationToken\"] = resp[\"NextContinuationToken\"]\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    return keys\n",
    "\n",
    "keys = get_all_s3_keys(raw_data_bucket, raw_data_prefix, \".tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1a86a-144f-41c6-9b48-67ee8124488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=[k for k in keys if len(k)<72] # ommiting the not required files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa47f3-26e6-4fe3-85fd-034646d61d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe873e16-86b5-4904-aacb-a2c0b24bd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the validation stats\n",
    "overall= pd.DataFrame(columns=[\"data\",\"min\",\"max\",\"mean\",\"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0b8c3-ebc0-43d6-8cb1-473d4accde32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Reproject the data \n",
    "# Define the source and target CRS\n",
    "# Also calculate raw - monthly validation stats\n",
    "os.makedirs(\"reproj\", exist_ok=True)\n",
    "src_crs = CRS.from_wkt('PROJCS[\"unknown\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Lambert_Conformal_Conic_2SP\"],PARAMETER[\"latitude_of_origin\",40],PARAMETER[\"central_meridian\",-97],PARAMETER[\"standard_parallel_1\",33],PARAMETER[\"standard_parallel_2\",45],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]')\n",
    "dst_crs = CRS.from_epsg(4326)  # WGS 84\n",
    "df = pd.DataFrame(columns=['filename', 'min(raw)', 'max(raw)', 'mean(raw)', 'std(raw)'])\n",
    "overall_raw= []\n",
    "for key in keys:\n",
    "    url = f\"s3://{raw_data_bucket}/{key}\"\n",
    "    with rasterio.open(url) as src:\n",
    "        filename_elements = key.split(\"/\")[-1].split(\".\")[:-1]\n",
    "        output_tif = \"_\".join(filename_elements) + \".tif\"\n",
    "        data = src.read(1)  # Read the first band\n",
    "        overall_raw.append(data)\n",
    "        \n",
    "        # Calculate statistics while ignoring NaN values\n",
    "        min_val = np.nanmin(data)\n",
    "        max_val = np.nanmax(data)\n",
    "        mean_val = np.nanmean(data)\n",
    "        std_val = np.nanstd(data)  \n",
    "        stats = [output_tif, min_val, max_val, mean_val, std_val]\n",
    "        df.loc[len(df)] = stats\n",
    "        \n",
    "        transform, width, height = calculate_default_transform(\n",
    "        src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'nodata': -9999\n",
    "        })\n",
    "\n",
    "        with rasterio.open(f\"reproj/{output_tif}\", 'w', **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                source=rasterio.band(src, i),\n",
    "                destination=rasterio.band(dst, i),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=dst_crs,\n",
    "                resampling=Resampling.nearest)\n",
    "        print(f\"Done for {output_tif}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b27b9-906b-4f58-aaf9-5fd97a6778c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall validation of raw data\n",
    "overall_raw= np.array(overall_raw)\n",
    "nan_min = np.nanmin(overall_raw)\n",
    "nan_max = np.nanmax(overall_raw)\n",
    "nan_mean = np.nanmean(overall_raw)\n",
    "nan_std = np.nanstd(overall_raw)\n",
    "overall.loc[len(overall)] = [\"raw\",nan_min,nan_max,nan_mean,nan_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56a809-0f19-4e8a-b2f6-c0923069b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation for reprojected data - yearly calculation\n",
    "overall_reproj = []\n",
    "files = glob.glob(\"reproj/*.tif\")\n",
    "df1 = pd.DataFrame(columns=['filename', 'min(reprojected)', 'max(reprojected)', 'mean(reprojected)', 'std(reprojected)'])\n",
    "for file in files:\n",
    "    with rasterio.open(file) as src:\n",
    "        filename_elements = file.split(\"/\")[-1].split(\".\")[:-1]\n",
    "        output_tif = \"_\".join(filename_elements) + \".tif\"\n",
    "        data = src.read(1)  \n",
    "        data = np.ma.masked_equal(data, -9999)\n",
    "        overall_reproj.append(data)\n",
    "        \n",
    "        # Calculate statistics while ignoring NaN values\n",
    "        min_val = np.nanmin(data)\n",
    "        max_val = np.nanmax(data)\n",
    "        mean_val = np.nanmean(data)\n",
    "        std_val = np.nanstd(data)  \n",
    "        stats = [output_tif, min_val, max_val, mean_val, std_val]\n",
    "        df1.loc[len(df1)] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e53c3c-53d7-46a2-bff0-9bdde717be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall validation of reprojected  data\n",
    "overall_reproj= np.array(overall_reproj)\n",
    "overall_reproj = np.ma.masked_equal(overall_reproj, -9999)\n",
    "nan_min = np.nanmin(overall_reproj)\n",
    "nan_max = np.nanmax(overall_reproj)\n",
    "nan_mean = np.nanmean(overall_reproj)\n",
    "nan_std = np.nanstd(overall_reproj)\n",
    "overall.loc[len(overall)] = [\"reprojected\",nan_min,nan_max,nan_mean,nan_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2be30-69b5-4300-b2a0-50f7c4ba6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Replace nan and 0 values with -9999 and multiply \n",
    "os.makedirs(\"reproj2\", exist_ok=True)\n",
    "files = glob.glob(\"reproj/*.tif\")\n",
    "for file in files:\n",
    "    filename = file.split('/')[-1]\n",
    "    xda = xarray.open_dataarray(file).sel(band=1)\n",
    "    # Multiply data\n",
    "    xda = xda.where(xda == -9999, xda * (44/12))\n",
    "\n",
    "\n",
    "     \n",
    "    data = xda.where(xda != 0, -9999)  # Replace 0 with -9999\n",
    "    #data = data.where(data != -3.4e+38, -9999)  # Replace -3.4e+38 with -9999\n",
    "    data = data.fillna(-9999)  # Ensure all NaNs are replaced with -9999\n",
    "    data_array = data.values\n",
    "    \n",
    "    \n",
    "\n",
    "    # Open the source raster to get metadata\n",
    "    with rasterio.open(file) as src:\n",
    "        meta = src.meta\n",
    "        meta.update({\n",
    "            'nodata': -9999,\n",
    "            'dtype': 'float32',\n",
    "            'driver': 'COG'\n",
    "        })\n",
    "        with rasterio.open(f\"reproj2/{filename}\", 'w', **meta) as dst:\n",
    "            dst.write(data_array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806d44f-34a3-4acc-a3df-3afb4b92e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation for reprojected data (non zero) - monthly calculation\n",
    "overall_reproj2=[]\n",
    "files = glob.glob(\"reproj/*.tif\")\n",
    "df11 = pd.DataFrame(columns=['filename', 'min(reproj_nonzero)', 'max(reproj_nonzero)', 'mean(reproj_nonzero)', 'std(reproj_nonzero)'])\n",
    "for file in files:\n",
    "    with rasterio.open(file) as src:\n",
    "        filename_elements = file.split(\"/\")[-1].split(\".\")[:-1]\n",
    "        output_tif = \"_\".join(filename_elements) + \".tif\"\n",
    "        data = src.read(1)  \n",
    "        data = np.ma.masked_where((data == -9999) | (data == 0), data)\n",
    "       \n",
    "\n",
    "        overall_reproj2.append(data)\n",
    "        # Calculate statistics while ignoring NaN values\n",
    "        min_val = np.nanmin(data)\n",
    "        max_val = np.nanmax(data)\n",
    "        mean_val = np.nanmean(data)\n",
    "        std_val = np.nanstd(data)  \n",
    "        stats = [output_tif, min_val, max_val, mean_val, std_val]\n",
    "        df11.loc[len(df11)] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e2627-78e6-43a2-9c34-86cd3e043121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation for reprojected data (non zero) - overall calculation\n",
    "overall_reproj2= np.array(overall_reproj2)\n",
    "overall_reproj2 = np.ma.masked_where((overall_reproj2 == -9999) | (overall_reproj2 == 0), overall_reproj2)\n",
    "nan_min = np.nanmin(overall_reproj2)\n",
    "nan_max = np.nanmax(overall_reproj2)\n",
    "nan_mean = np.nanmean(overall_reproj2)\n",
    "nan_std = np.nanstd(overall_reproj2)\n",
    "overall.loc[len(overall)] = [\"reprojected_non_zero\",nan_min,nan_max,nan_mean,nan_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf75b9f-c330-4d31-985c-ce78c3f77896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: To put overviews\n",
    "COG_PROFILE = {\"driver\": \"COG\", \"compress\": \"DEFLATE\"}\n",
    "OVERVIEW_LEVELS = 9\n",
    "OVERVIEW_RESAMPLING = 'average'\n",
    "\n",
    "for file in glob.glob(\"reproj2/*.tif\"):\n",
    "    output_path = f\"output/{file.split(\"/\")[-1]}\"\n",
    "    \n",
    "    # Create a temporary file to hold the COG\n",
    "    with tempfile.NamedTemporaryFile(suffix='.tif', delete=False) as temp_file:       \n",
    "        # Create COG with overviews and nodata value\n",
    "        cog_translate(\n",
    "            file,\n",
    "            temp_file.name,\n",
    "            cog_profiles.get(\"deflate\"),\n",
    "            overview_level=OVERVIEW_LEVELS,\n",
    "            overview_resampling=OVERVIEW_RESAMPLING,\n",
    "            nodata=-9999\n",
    "        )\n",
    "        # Move the temporary file to the desired local path\n",
    "        os.rename(temp_file.name, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da3a099-bf4c-4210-87a4-ee5934732303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation for final data with overviews - overall calculation\n",
    "overall_final=[]\n",
    "files = glob.glob(\"output/*.tif\")\n",
    "df2 = pd.DataFrame(columns=['filename', 'min(transformed)', 'max(transformed)', 'mean(transformed)', 'std(transformed)'])\n",
    "for file in files:\n",
    "    with rasterio.open(file) as src:\n",
    "        filename_elements = file.split(\"/\")[-1].split(\".\")[:-1]\n",
    "        output_tif = \"_\".join(filename_elements) + \".tif\"\n",
    "        data = src.read(1)  # Read the first band\n",
    "        \n",
    "        # Mask -9999 values and NaNs for statistics calculation\n",
    "        data = np.ma.masked_where((data == -9999) | np.isnan(data), data)\n",
    "        # Multiply data - undo the multiplication done during transformation\n",
    "        data = data *( 12/44)\n",
    "        overall_final.append(data)\n",
    "        \n",
    "        # Calculate statistics while ignoring NaN values\n",
    "        min_val = np.nanmin(data)\n",
    "        max_val = np.nanmax(data)\n",
    "        mean_val = np.nanmean(data)\n",
    "        total = np.nansum(data) \n",
    "        std_val = np.nanstd(data)  \n",
    "        stats = [output_tif, min_val, max_val, mean_val, std_val]\n",
    "        df2.loc[len(df2)] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f7d75-a883-4071-8541-0635fc217f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation for final data (with overviews) - overall calculation\n",
    "overall_final= np.array(overall_final)\n",
    "overall_final = np.ma.masked_where((overall_final == -9999) | np.isnan(overall_final), overall_final)\n",
    "nan_min = np.nanmin(overall_final)\n",
    "nan_max = np.nanmax(overall_final)\n",
    "nan_mean = np.nanmean(overall_final)\n",
    "nan_std = np.nanstd(overall_final)\n",
    "overall.loc[len(overall)] = [\"Transformed\",nan_min,nan_max,nan_mean,nan_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722588b-b2f0-4556-be2d-ad86b2403334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to json\n",
    "overall.to_json(\"overall_stats.json\")\n",
    "pd.merge(pd.merge(df,df1, on='filename', how='inner'), pd.merge(df11,df2, on='filename', how='inner'), how='inner',on='filename' ).to_json(\"yearly_stats.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
